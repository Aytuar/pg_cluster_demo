data_directory = '/var/lib/postgresql/9.5/main'		# use data in another directory
hba_file = '/etc/postgresql/9.5/main/pg_hba.conf'	# host-based authentication file
ident_file = '/etc/postgresql/9.5/main/pg_ident.conf'	# ident configuration file

external_pid_file = '/var/run/postgresql/9.5-main.pid'			# write an extra PID file

listen_addresses='*'
port = 5432				# (change requires restart)
max_connections = 10 # should be bigger than (`pgbouncer default_pool_size` * `number of instances`) (it is 3000 now, so we have 100 spare connections for backups and cannon)
unix_socket_directories = '/var/run/postgresql'	# comma-separated list of directories

ssl = true				# (change requires restart)
ssl_cert_file = '/etc/ssl/certs/ssl-cert-snakeoil.pem'		# (change requires restart)
ssl_key_file = '/etc/ssl/private/ssl-cert-snakeoil.key'		# (change requires restart)
ssl_renegotiation_limit = 0 # 9.4.4 default is 512MB

datestyle = 'iso, mdy'
timezone = 'localtime'

lc_messages = 'en_US.UTF-8'			# locale for system error message
lc_monetary = 'en_US.UTF-8'			# locale for monetary formatting
lc_numeric = 'en_US.UTF-8'			# locale for number formatting
lc_time = 'en_US.UTF-8'				# locale for time formatting

default_text_search_config = 'pg_catalog.english'

# checkpoints tuning
min_wal_size = 160MB
max_wal_size = 1GB
wal_compression = on
checkpoint_timeout = 10min
checkpoint_completion_target = 0.9

# autovacuum general tuning
track_counts = on
vacuum_freeze_min_age = 1000000 # estimation based on xid/s rate (~ 20/s) measured on production servers
vacuum_multixact_freeze_min_age = 500000 # 1/2 of vacuum_freeze_min_age
autovacuum_freeze_max_age = 1000000000 # 1B
vacuum_freeze_table_age = 800000000 # 0.8B to have a room for manual vacuum freeze before autovacuum_freeze_max_age
autovacuum_multixact_freeze_max_age = 1000000000 # 1B, repeat autovacuum_freeze_max_age
vacuum_multixact_freeze_table_age = 800000000 # 0.8B repeat vacuum_freeze_table_age

# adhoc formula here : 1000ms / autovacuum_vacuum_cost_delay  = X awakes/s
# X * autovacuum_vacuum_cost_delay = Y cost/sec
# rate MB/s = Y/cost * 8kb (kb, block size)
# Real example : dirty_cost=20, X = 1000ms/20ms = 50, Y = 50 * 100 = 5000, rate(MB/s) = 5000/20 * 8kb  = 1.9MB/s
# Example : misses_cost=10, ... , rate(MB/s) = 5000/20*8192 = 3.8MB/s
autovacuum_vacuum_cost_limit = 200 # vacuum_cost_limit=-1 making vacuum works at full power while  autovacuum process being less disruptive
autovacuum_vacuum_cost_delay = 10ms # ~8Mb/s for dirty, ~16Mb/s for misses (
autovacuum_vacuum_scale_factor = 0.05 # lowering because of large tables can be never vacuumed
autovacuum_analyze_scale_factor = 0.025 # analyze more often (large tables)
autovacuum_naptime = 10min # wake up 1 worker per db every 10min/db_num = ~3sec (worst case). adjusted due to 200 database limit 
autovacuum_max_workers = 4
autovacuum_work_mem = 64MB # each autovacuum worker max memory allocation

# memory tuning
work_mem = 8MB
temp_buffers = 8MB
shared_buffers = 64MB
maintenance_work_mem = 64MB # min 1MB, used by manual VACUUM, ALTER TABLE, CREATE INDEX

shared_preload_libraries = 'repmgr_funcs, pg_stat_statements, auto_explain'

# statements statistics module settings
pg_stat_statements.max  = 5000
pg_stat_statements.track = all
pg_stat_statements.save = true
track_activity_query_size = 16000

# backhround writer tuning
bgwriter_lru_maxpages = 500		# 0-1000 max buffers written/round

# lock management
deadlock_timeout = 3s

# planner cost constants 
effective_cache_size = 512MB

# logging
log_temp_files = 8000
log_autovacuum_min_duration = 1000
log_line_prefix = '%t %p %d '  # t - time, p - pid, d - database name
log_timezone = 'UTC'  # force to use UTC
log_lock_waits = on
log_checkpoints = on  # useful checkpoint stat (logged once every 10 mins)
log_statement = ddl  # log ddl queries if any 
log_connections = on  # as we use pgbouncer for proxying connections there shouldn't be more that one log entry per uwsgi worker per pgbouncer.server_lifetime(2 mins)
auto_explain.log_min_duration = '5s'  # track statements which run longer than that and registering EXPLAIN automatically
auto_explain.log_nested_statements = on  # tracks sql inside procedures as top level queries

wal_log_hints = on 

# Replication settings
hot_standby = on

# Allow read-only queries on standby servers. The number of WAL
# senders should be larger than the number of standby servers.
wal_level = 'hot_standby'

max_wal_senders = 4 # as many as 4 standby servers are possible to have for this master
max_replication_slots = 12  # guess value , 4 slots per replica should be more than enough

# Enable archiving, but leave it unconfigured (so that it can be
# configured without a restart later). Recommended, not required.
archive_mode = on
archive_command = 'cd .'

# For lond running queries to be not cancelled on master updates
# Defer removal of dead rows on master, may cause some bloat. But if to make backups during inactivity it is fine.
# From the doc :  the cleanup situation will be no worse than if the standby queries were running directly on the primary server,
# and you are still getting the benefit of off-loading execution onto the standby
hot_standby_feedback = on
max_standby_streaming_delay = 300s

#include 'postgresql.conf.override'
